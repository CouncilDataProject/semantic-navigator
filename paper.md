# Paper

## Primary Sections

### Journalistic Narrative Construction

* Journalistic narrative construction is the practice of finding, researching, and writing a news story.
  * The news can be for local journalists covering a small council meeting or for larger investigative reports.
* In this domain, tools for supporting journalistic narrative construction tend to fall into one of two categories, passive support, or active use.
* Tools which passively support journalists are ones which computationally discover and notify the journalist of potentially outline documents or information.
* For example, Big Local News, an initiative from Stanford, is creating the AgendaWatch platform to collect and mine hundreds of thousands public meeting documents from across the United States in to enable the detection and notification of outlier events and meetings.
  * The idea is in detecting "newsworthiness," finding potentially hot-topic issues in meeting agendas and notifying journalists of the meeting.
* Tools which require active participation from a user are different. These tend to focus on assisting in more in-depth discovery of related or similar documents and providing a method for easily gaining additional context while again, enabling search.
  * Active use tools tend to focus on large scale document mining techniques such as summarization, topical clustering, and some specialized search methods.

* Our work falls more into the active use category in creating new methods for improved search, discovery, and contextual understanding.
* We approach search not from a keyword based index but rather from semantic similarity and active learning classification alone.
* This, we believe, will assist users in freely narrowing their search towards a semantic understanding rather than adding facets and filters.

* TODO: find more papers on passive and active use narrative construction

### Archival Search and Discovery

* Tools for archival search and discovery tend to be similar to tools for active use narrative construction.
* Such tools are mainly focused on enabling analysis assisted search by auto-generating plots during the search process that help guide the user across time or topic.
* ClioQuery is one example of such...
* TODO: cite another paper
* As these are tools which focus on archival, one common aspect amongest them is the addition and availability of date data for items in the collection.
* Date information is used for creating timeline plots of mentions of the keyword over time like that of an ngram viewer (TODO CITE)
* Lee's Newspaper Navigator however allows users to filter by date but doesn't provide any analysis methods.
  * Newspaper Navigator however was one of the first projects to enable search via active learning using semantic embeddings comprised of both visual encodings and text encodings from metadata.
  * Lee's work demonstrates how keywords alone aren't enough to filter and narrow search in the 1 million + document domain.
  * Instead, allowing users to narrow their search towards a semantic concept rather than a single or combination keyword.

* This study questions how this semantic and active learning search approach can be applied to text corpora.
* Rather than searching through archival images we search through snippets of Seattle City Council meetings.
* This is a test to see if an active learing approach may work in this context due to the possibly larger duration of time spent annotating text rather than images.

### Data Collection and Structure

* We create a corpus of documents for testing from Seattle City Council meeting transcripts for meetings between 2020 and 2023 collected and generated by Council Data Project (TODO: CITE).
* This includes subcommittee meetings and full council meetings of the Seattle City Council.
* We process each transcript into chunks of text with each chunk being cut off at the nearest sentence past the 1024 character.
* Along with the text of each chunk we attach the CDP metadata from which that chunk came (the CDP managed event id, session id, session datetime, etc.).
* We additionally generate a unique id for the chunk itself.
* Finally, we generate semantic embeddings for each chunk using sentencetransformers and the "all-MiniLM-L12-v2" model (TODO: cite sentencetransformers, transformers, and model)


* Once we have created the semantic embeddings, we store each text chunk to an individual text file.
* The completed dataset removes the text column and instead stores the path to the text file.

* TODO: EXAMPLE TABLE OF DATASET

* By precomputing the embeddings and creating a unique file for each piece of text, we are able to create a dataset that is fast to load while retaining all of the metadata and semantic data needed for querying and training and leaving the text to be loaded as needed.

* Our completed dataset consisted of N number of unique chunks of text.
* TODO: DETERMINE DATASET SIZE

### Limitations

## Support Sections

### Results User Study

* Across all five users, there was a struggle to understand our "relevant" and "irrelevant" narrowing functionality.
* Instead of using the "relevant" and "irrelevant" to narrow to their own further search, each user was labeling items as "relevant" or "irrelevant" to their original broader search.

* TODO: get quote of someone saying "all of these are relevant"

* This could have been a failure of the website design and documentation available on the page or of the user study itself.

* As this was the primary thing we wanted to test, we cannot say how well this task was performed.

* Even after prodding users down the path of using the "relevant" and "irrelevant" buttons to narrow their search, many stated how this is an entirely new concept to them.

* TODO: get quote of someone discussing how this search is entirely different from their normal methods